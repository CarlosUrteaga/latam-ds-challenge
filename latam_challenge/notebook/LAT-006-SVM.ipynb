{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54a8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown as md\n",
    "from datetime import date, datetime\n",
    "%matplotlib inline\n",
    "#sns.set(rc={\"figure.figsize\":(20, 20)})\n",
    "\n",
    "from pandas import DataFrame\n",
    "from typing import List\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7da16614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS\n",
    "FECHAI = 'Fecha-I'\n",
    "FECHAO = 'Fecha-O'\n",
    "VLOO = 'Vlo-O'\n",
    "ORIO = 'Ori-O'\n",
    "DESO = 'Des-O'\n",
    "EMPO = 'Emp-O'\n",
    "VLOI = 'Vlo-I'\n",
    "DIA = 'DIA'\n",
    "MES = 'MES'\n",
    "ANIO = 'A칌O'\n",
    "DIANOM = 'DIANOM'\n",
    "TIPOVUELO = 'TIPOVUELO'\n",
    "OPERA = 'OPERA'\n",
    "SIGLADES = 'SIGLADES'\n",
    "COHORT = 'cohort'\n",
    "# \n",
    "TEMPORADA_ALTA = 'temporada_alta'\n",
    "DIF_MIN = 'dif_min'\n",
    "ATRASO_15 = 'atraso_15'\n",
    "PERIODO_DIA = 'periodo_dia'\n",
    "MORNING = 'ma침ana'\n",
    "AFTERNOON = 'tarde'\n",
    "NIGHT = 'noche'\n",
    "\n",
    "\n",
    "DATE = 'Date'\n",
    "TIME = 'time'\n",
    "HOUR = 'hour'\n",
    "MINUTE = 'minute'\n",
    "\n",
    "\n",
    "COLUM_FILTER = [FECHAI,VLOI, DIA, MES, ANIO, DIANOM, TIPOVUELO, OPERA, SIGLADES, TEMPORADA_ALTA, ATRASO_15, PERIODO_DIA]\n",
    "COLUM_SYNTHETIC_FEATURES = [TEMPORADA_ALTA, DIF_MIN, ATRASO_15, PERIODO_DIA, 'AnteriorDelay', 'AnteriorEarly']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "STR_WINTER_START = '2017-12-15'\n",
    "STR_WINTER_END = '2017-12-31'\n",
    "STR_WINTER_BIS_START = '2017-01-01'\n",
    "STR_WINTER_BIS_END = '2017-03-03'\n",
    "STR_JULY_START = '2017-07-15'\n",
    "STR_JULY_END = '2017-07-31'\n",
    "STR_SEPT_START = '2017-09-11'\n",
    "STR_SEPT_END = '2017-09-30'\n",
    "\n",
    "\n",
    "STR_MANANA_START= '5:00'\n",
    "STR_MANANA_END = '11:59'\n",
    "STR_TARDE_START = '12:00'\n",
    "STR_TARDE_END = '18:59'\n",
    "\n",
    "PARAM_GRID = {\n",
    "    'n_estimators': [10, 20, 50, 10, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [4, 8, 16, 32, 64, 128, 256, 512],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_jobs': [2]\n",
    "}\n",
    "\n",
    "\n",
    "columns = [TEMPORADA_ALTA, DIF_MIN, ATRASO_15, PERIODO_DIA]\n",
    "def convert_str_to_date(str_date: str) -> datetime:\n",
    "    \"\"\"convert string to date format '%Y-%m-%d'\n",
    "\n",
    "    Args:\n",
    "        str_date (str): string ex: '2017-01-01'\n",
    "\n",
    "    Returns:\n",
    "        datetime: string with datetime type\n",
    "    \"\"\"\n",
    "    return datetime.strptime(str_date, '%Y-%m-%d').date()\n",
    "\n",
    "def convert_str_to_time(str_date: str) -> datetime:\n",
    "    \"\"\"convert string to time format '%H:%M'\n",
    "\n",
    "    Args:\n",
    "        str_date (str): string '23:59'\n",
    "\n",
    "    Returns:\n",
    "        datetime: string with datetime type\n",
    "    \"\"\"\n",
    "    return datetime.strptime(str_date, '%H:%M').time()\n",
    "\n",
    "def add_temporada_alta_flag(df: DataFrame, dates: List) -> DataFrame:\n",
    "    \"\"\"Add temporada alta flag according to array of dates\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): _description_\n",
    "        dates (List): _description_\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: _description_\n",
    "    \"\"\"\n",
    "    df[TEMPORADA_ALTA] = 0\n",
    "    for date in dates:\n",
    "        df.loc[(df[DATE] >= date[0]) & (df[DATE]<=date[1]), TEMPORADA_ALTA] = 1\n",
    "    return df.copy()\n",
    "def add_periodo_dia_flag(df: DataFrame, times: List) -> DataFrame:\n",
    "    \"\"\"Add temporada alta flag according to array of dates\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): _description_\n",
    "        dates (List): _description_\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: _description_\n",
    "    \"\"\"\n",
    "    # default\n",
    "    df[PERIODO_DIA] = NIGHT\n",
    "    df.loc[(df[TIME] >= times[0][0]) & (df[TIME]<=times[0][1]), PERIODO_DIA] = MORNING\n",
    "    df.loc[(df[TIME] >= times[1][0]) & (df[TIME]<=times[1][1]), PERIODO_DIA] = AFTERNOON\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ac15a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temporada_alta_set()-> list:\n",
    "    \"\"\"\n",
    "    This function generate arrays to generate temporada_alta elements, source from constant\n",
    "    dates ahre the following, \n",
    "        15-Dic y 3-Mar, o 15-Jul y 31-Jul, o 11-Sep y 30-Sep,\n",
    "    output: array of element, with the following \n",
    "    \"\"\"\n",
    "    str_winter_start = convert_str_to_date(STR_WINTER_START)\n",
    "    str_winter_end = convert_str_to_date(STR_WINTER_END)\n",
    "    str_winter_bis_start = convert_str_to_date(STR_WINTER_BIS_START)\n",
    "    str_winter_bis_end = convert_str_to_date(STR_WINTER_BIS_END)\n",
    "    str_July_start = convert_str_to_date(STR_JULY_START)\n",
    "    str_July_end = convert_str_to_date(STR_JULY_END)\n",
    "    str_Sept_start = convert_str_to_date(STR_SEPT_START)\n",
    "    str_Sept_end = convert_str_to_date(STR_SEPT_END)\n",
    "\n",
    "    dates = [[str_winter_start, str_winter_end],\n",
    "             [str_winter_bis_start, str_winter_bis_end],\n",
    "             [str_July_start, str_July_end],\n",
    "             [str_Sept_start, str_Sept_end]]\n",
    "    return dates\n",
    "\n",
    "def generate_day_section():\n",
    "    \"\"\"\n",
    "    split a day iin three part, morning, afternoon and night\n",
    "    \"\"\"\n",
    "    str_ma침ana_start = convert_str_to_time(STR_MANANA_START)\n",
    "    str_ma침ana_end = convert_str_to_time(STR_MANANA_END)\n",
    "    str_tarde_start = convert_str_to_time(STR_TARDE_START)\n",
    "    str_tarde_end = convert_str_to_time(STR_TARDE_END)\n",
    "    times = [[str_ma침ana_start, str_ma침ana_end],\n",
    "             [str_tarde_start, str_tarde_end],\n",
    "            ]\n",
    "    return times\n",
    "\n",
    "def split_date(df:DataFrame, column_name:str)-> DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): _description_\n",
    "        column_name (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: _description_\n",
    "    \"\"\"\n",
    "    df[column_name] = pd.to_datetime(df[column_name])\n",
    "    df[DATE] = df[column_name].dt.date\n",
    "    df[TIME] = df[column_name].dt.time\n",
    "    return df.copy()\n",
    "\n",
    "def add_temporada_alta_flag(df: DataFrame, dates: List) -> DataFrame:\n",
    "    \"\"\"Add temporada alta flag according to array of dates\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): _description_\n",
    "        dates (List): _description_\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: _description_\n",
    "    \"\"\"\n",
    "    df[TEMPORADA_ALTA] = 0\n",
    "    for date in dates:\n",
    "        df.loc[(df[DATE] >= date[0]) & (df[DATE]<=date[1]), TEMPORADA_ALTA] = 1\n",
    "    return df.copy()\n",
    "\n",
    "def add_periodo_dia_flag(df: DataFrame, times: List) -> DataFrame:\n",
    "    \"\"\"Add temporada alta flag according to array of dates\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): _description_\n",
    "        dates (List): _description_\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: _description_\n",
    "    \"\"\"\n",
    "    # default\n",
    "    df[PERIODO_DIA] = NIGHT\n",
    "    df.loc[(df[TIME] >= times[0][0]) & (df[TIME]<=times[0][1]), PERIODO_DIA] = MORNING\n",
    "    df.loc[(df[TIME] >= times[1][0]) & (df[TIME]<=times[1][1]), PERIODO_DIA] = AFTERNOON\n",
    "    return df.copy()\n",
    "\n",
    "def add_dif_min_and_atraso_15(df:DataFrame) ->DataFrame:\n",
    "    df[DIF_MIN] = df[FECHAO]-df[FECHAI]\n",
    "    df[DIF_MIN] = df[DIF_MIN].dt.total_seconds()//60\n",
    "    df[ATRASO_15] = 0\n",
    "    df.loc[df[DIF_MIN]>15, ATRASO_15] = 1\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4df247cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5190a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_operational_columns(df:DataFrame)-> DataFrame:\n",
    "    del df[FECHAO]\n",
    "    del df[VLOO]\n",
    "    del df[ORIO]\n",
    "    del df[DESO]\n",
    "    del df[EMPO]\n",
    "    return df\n",
    "\n",
    "def filter_column(df:DataFrame, columns:str =  COLUM_FILTER)->DataFrame:\n",
    "    return df[columns]\n",
    "\n",
    "def previous_flight (df):\n",
    "    df[\"Early\"] = df[DIF_MIN].shift(-1)\n",
    "    df['AnteriorEarly'] = 0\n",
    "    df.loc[df[\"Early\"]<0, 'AnteriorEarly'] = 1\n",
    "    df[\"Delay\"] = df[ATRASO_15].shift(-1)\n",
    "    df['AnteriorDelay'] = 0\n",
    "    df.loc[df[\"Delay\"]>0, 'AnteriorDelay'] = 1\n",
    "    return df\n",
    "\n",
    "def one_hot_encoder(df:DataFrame)-> DataFrame:\n",
    "    \n",
    "    df = pd.get_dummies(df, columns = [OPERA])\n",
    "    df = pd.get_dummies(df, columns = [SIGLADES])\n",
    "    df = pd.get_dummies(df, columns = [TEMPORADA_ALTA]) \n",
    "    df = pd.get_dummies(df, columns = [PERIODO_DIA]) \n",
    "    df = pd.get_dummies(df, columns = [VLOI])\n",
    "    df = pd.get_dummies(df, columns = [DIANOM])\n",
    "    return df \n",
    "\n",
    "\n",
    "def to_bool_tipo_vuelo(df:DataFrame)-> DataFrame:\n",
    "    df[f\"{TIPOVUELO}_\"] = df[TIPOVUELO]\n",
    "    df.loc[df[f\"{TIPOVUELO}_\"]== 'I', TIPOVUELO] = 1\n",
    "    df.loc[df[f\"{TIPOVUELO}_\"]== 'N', TIPOVUELO] = 0\n",
    "    del df[f\"{TIPOVUELO}_\"]\n",
    "    return df\n",
    "\n",
    "def fit_grid_model(\n",
    "    rfc: RandomForestClassifier,\n",
    "    param_grid,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "):  # pragma: no cover\n",
    "    \"\"\"GridSeach\n",
    "\n",
    "    Args:\n",
    "        rfc (RandomForestClassifier): ML Model\n",
    "        param_grid (dict): JSON parameters\n",
    "        X_train (pd.DataFrame): train df\n",
    "        y_train (pd.DataFrame): goal df\n",
    "        model_type (str): model name\n",
    "\n",
    "    Returns:\n",
    "        [type]: model trained\n",
    "    \"\"\"\n",
    "    model = GridSearchCV(\n",
    "        estimator=rfc,\n",
    "        param_grid=param_grid,\n",
    "        cv=3,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "62378d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = generate_temporada_alta_set()\n",
    "times = generate_day_section()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37ef969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../sources/raw/dataset_SCL.csv\", dtype={'Vlo-O':str, 'Vlo-I':str})\n",
    "df[FECHAO] = pd.to_datetime(df[FECHAO])\n",
    "df = (df.pipe(split_date, FECHAI)\n",
    "        .pipe(add_temporada_alta_flag, dates)\n",
    "        .pipe(add_periodo_dia_flag, times)\n",
    "        #.pipe(apply_cohort)\n",
    "        .pipe(add_dif_min_and_atraso_15)\n",
    "        .pipe(delete_operational_columns)\n",
    "        .pipe(filter_column)\n",
    "        .pipe(to_bool_tipo_vuelo)\n",
    "        #.pipe(one_hot_encoder) # generate one_hot_encoder\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95d9a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = df.copy()\n",
    "df = one_hot_encoder(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f85c7",
   "metadata": {},
   "source": [
    "no sirven\n",
    "* Ori-I y Pri-o un s칩lo lugar de origen\n",
    "* Des-I y SIGLADES son lo mismo\n",
    "- OPERA == Emp-I\n",
    "\n",
    "modificadores\n",
    "- Vlo-I != Vlo-O, es diferente hubo atrasosi el n칰mero de vuelo cambio o el origen cambio, significa un retraso? Des-I\n",
    "- Des-I != Des-O, es diferente, atraso\n",
    "# no se usaran para evitar sesgos\n",
    "- Fecha-O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56653e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha-I</th>\n",
       "      <th>DIA</th>\n",
       "      <th>MES</th>\n",
       "      <th>A칌O</th>\n",
       "      <th>TIPOVUELO</th>\n",
       "      <th>atraso_15</th>\n",
       "      <th>OPERA_Aerolineas Argentinas</th>\n",
       "      <th>OPERA_Aeromexico</th>\n",
       "      <th>OPERA_Air Canada</th>\n",
       "      <th>OPERA_Air France</th>\n",
       "      <th>...</th>\n",
       "      <th>Vlo-I_993</th>\n",
       "      <th>Vlo-I_9955</th>\n",
       "      <th>Vlo-I_9956</th>\n",
       "      <th>DIANOM_Domingo</th>\n",
       "      <th>DIANOM_Jueves</th>\n",
       "      <th>DIANOM_Lunes</th>\n",
       "      <th>DIANOM_Martes</th>\n",
       "      <th>DIANOM_Miercoles</th>\n",
       "      <th>DIANOM_Sabado</th>\n",
       "      <th>DIANOM_Viernes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 23:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02 23:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03 23:30:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-04 23:30:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-05 23:30:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68201</th>\n",
       "      <td>2017-12-22 14:55:00</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68202</th>\n",
       "      <td>2017-12-25 14:55:00</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68203</th>\n",
       "      <td>2017-12-27 14:55:00</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68204</th>\n",
       "      <td>2017-12-29 14:55:00</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68205</th>\n",
       "      <td>2017-12-31 14:55:00</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68206 rows 칑 687 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Fecha-I  DIA  MES   A칌O TIPOVUELO  atraso_15  \\\n",
       "0     2017-01-01 23:30:00    1    1  2017         1          0   \n",
       "1     2017-01-02 23:30:00    2    1  2017         1          0   \n",
       "2     2017-01-03 23:30:00    3    1  2017         1          0   \n",
       "3     2017-01-04 23:30:00    4    1  2017         1          0   \n",
       "4     2017-01-05 23:30:00    5    1  2017         1          0   \n",
       "...                   ...  ...  ...   ...       ...        ...   \n",
       "68201 2017-12-22 14:55:00   22   12  2017         1          1   \n",
       "68202 2017-12-25 14:55:00   25   12  2017         1          1   \n",
       "68203 2017-12-27 14:55:00   27   12  2017         1          1   \n",
       "68204 2017-12-29 14:55:00   29   12  2017         1          0   \n",
       "68205 2017-12-31 14:55:00   31   12  2017         1          0   \n",
       "\n",
       "       OPERA_Aerolineas Argentinas  OPERA_Aeromexico  OPERA_Air Canada  \\\n",
       "0                                0                 0                 0   \n",
       "1                                0                 0                 0   \n",
       "2                                0                 0                 0   \n",
       "3                                0                 0                 0   \n",
       "4                                0                 0                 0   \n",
       "...                            ...               ...               ...   \n",
       "68201                            0                 0                 0   \n",
       "68202                            0                 0                 0   \n",
       "68203                            0                 0                 0   \n",
       "68204                            0                 0                 0   \n",
       "68205                            0                 0                 0   \n",
       "\n",
       "       OPERA_Air France  ...  Vlo-I_993  Vlo-I_9955  Vlo-I_9956  \\\n",
       "0                     0  ...          0           0           0   \n",
       "1                     0  ...          0           0           0   \n",
       "2                     0  ...          0           0           0   \n",
       "3                     0  ...          0           0           0   \n",
       "4                     0  ...          0           0           0   \n",
       "...                 ...  ...        ...         ...         ...   \n",
       "68201                 0  ...          0           0           0   \n",
       "68202                 0  ...          0           0           0   \n",
       "68203                 0  ...          0           0           0   \n",
       "68204                 0  ...          0           0           0   \n",
       "68205                 0  ...          0           0           0   \n",
       "\n",
       "       DIANOM_Domingo  DIANOM_Jueves  DIANOM_Lunes  DIANOM_Martes  \\\n",
       "0                   1              0             0              0   \n",
       "1                   0              0             1              0   \n",
       "2                   0              0             0              1   \n",
       "3                   0              0             0              0   \n",
       "4                   0              1             0              0   \n",
       "...               ...            ...           ...            ...   \n",
       "68201               0              0             0              0   \n",
       "68202               0              0             1              0   \n",
       "68203               0              0             0              0   \n",
       "68204               0              0             0              0   \n",
       "68205               1              0             0              0   \n",
       "\n",
       "       DIANOM_Miercoles  DIANOM_Sabado  DIANOM_Viernes  \n",
       "0                     0              0               0  \n",
       "1                     0              0               0  \n",
       "2                     0              0               0  \n",
       "3                     1              0               0  \n",
       "4                     0              0               0  \n",
       "...                 ...            ...             ...  \n",
       "68201                 0              0               1  \n",
       "68202                 0              0               0  \n",
       "68203                 1              0               0  \n",
       "68204                 0              0               1  \n",
       "68205                 0              0               0  \n",
       "\n",
       "[68206 rows x 687 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ee44cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "columns = columns.tolist()\n",
    "columns.remove(FECHAI)\n",
    "df = df[columns]\n",
    "columns.remove(ATRASO_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8ad6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[columns],\n",
    "        df[ATRASO_15],\n",
    "        test_size=.8,\n",
    "        random_state=42,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df6ef02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "149ffe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 4 new classifiers\n",
    "clfs = {\"Logistic Regression\": LogisticRegression(solver = 'saga',  random_state=0,  max_iter=99999990 ),\n",
    "        \"Support Vector rbf\": SVC(kernel='rbf'),\n",
    "        \"Support Vector sigmoid\": SVC(kernel='sigmoid'),\n",
    "        \"KNN\":KNeighborsClassifier(n_neighbors=15),\n",
    "        \"Decision Tree\": DecisionTreeClassifier()\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b7f835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def feature_importance(clf, X, y, top_limit=None):\n",
    "\n",
    "    # Retrieve the Bunch object after 50 repeats\n",
    "    # n_repeats is the number of times that each feature was permuted to compute the final score\n",
    "    bunch = permutation_importance(clf, X, y,\n",
    "                                 n_repeats=50, random_state=42)\n",
    "\n",
    "    # Average feature importance\n",
    "    imp_means = bunch.importances_mean\n",
    "\n",
    "    # List that contains the index of each feature in descending order of importance\n",
    "    ordered_imp_means_args = np.argsort(imp_means)[::-1]\n",
    "\n",
    "    # If no limit print all features\n",
    "    if top_limit is None:\n",
    "        top_limit = len(ordered_imp_means_args)\n",
    "\n",
    "    # Print relevant information\n",
    "    for i, _ in zip(ordered_imp_means_args, range(top_limit)):\n",
    "        name = data.feature_names[i]\n",
    "        imp_score = imp_means[i]\n",
    "        imp_std = bunch.importances_std[i]\n",
    "        print(f\"Feature {name} with index {i} has an average importance score of {imp_score:.3f} +/- {imp_std:.3f}\\n\")\n",
    "        # Compute feature importance on the test set given a classifier\n",
    "\n",
    "def fit_compute_importance(clf, k = 4):\n",
    "    kf = KFold(n_splits=k, random_state=None)\n",
    "    result = cross_val_score(clf , X_train, y_train, cv = kf)\n",
    "\n",
    "    print(f\"cross-validation Avg accuracy: {result.mean()}\")\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"Mean accuracy score on the test set: {clf.score(X_test, y_test)*100:.2f}%\\n\")\n",
    "    # print(f\"游늺 Mean accuracy score on the test set: {clf.score(X_test, y_test)*100:.2f}%\\n\")\n",
    "    # print(\"游댛 Top 4 features when using the test set:\\n\")\n",
    "    #feature_importance(clf, X_test, y_test, top_limit=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e27e889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Logistic Regression classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8107913331974954\n",
      "Mean accuracy score on the test set: 81.61%\n",
      "\n",
      "====================================================================================================\n",
      "Support Vector rbf classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8107913331974954\n",
      "Mean accuracy score on the test set: 81.61%\n",
      "\n",
      "====================================================================================================\n",
      "Support Vector sigmoid classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8107913331974954\n",
      "Mean accuracy score on the test set: 81.61%\n",
      "\n",
      "====================================================================================================\n",
      "KNN classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8111579880858117\n",
      "Mean accuracy score on the test set: 81.50%\n",
      "\n",
      "====================================================================================================\n",
      "Decision Tree classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.7508979057749166\n",
      "Mean accuracy score on the test set: 74.90%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for name, clf in clfs.items():\n",
    "    print(\"=====\"*20)\n",
    "    print(f\"{name} classifier\\n\")\n",
    "    fit_compute_importance(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6398e663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192797580866856"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_st = RandomForestClassifier(random_state=42)\n",
    "model = fit_grid_model(rfc_st, PARAM_GRID, X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9f4a75",
   "metadata": {},
   "source": [
    "# adding new feature Early Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0f153e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../sources/raw/dataset_SCL.csv\", dtype={'Vlo-O':str, 'Vlo-I':str})\n",
    "df[FECHAO] = pd.to_datetime(df[FECHAO])\n",
    "df = (df.pipe(split_date, FECHAI)\n",
    "        .pipe(add_temporada_alta_flag, dates)\n",
    "        .pipe(add_periodo_dia_flag, times)\n",
    "        #.pipe(apply_cohort)\n",
    "        .pipe(add_dif_min_and_atraso_15)\n",
    "        .pipe(delete_operational_columns)\n",
    "        .pipe(previous_flight)\n",
    "        .pipe(filter_column)\n",
    "        .pipe(to_bool_tipo_vuelo)\n",
    "        .pipe(one_hot_encoder) # generate one_hot_encoder\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c63b670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "columns = columns.tolist()\n",
    "columns.remove(FECHAI)\n",
    "df = df[columns]\n",
    "columns.remove(ATRASO_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "59027d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[columns],\n",
    "        df[ATRASO_15],\n",
    "        test_size=.8,\n",
    "        random_state=42,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f8bb8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 4 new classifiers\n",
    "clfs = {\"Logistic Regression\": LogisticRegression(solver = 'saga',  random_state=0,  max_iter=99999990 ),\n",
    "        \"Support Vector rbf\": SVC(kernel='rbf'),\n",
    "        \"Support Vector sigmoid\": SVC(kernel='sigmoid'),\n",
    "        \"KNN\":KNeighborsClassifier(n_neighbors=15),\n",
    "        \"Decision Tree\": DecisionTreeClassifier()\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b1850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Logistic Regression classifier\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for name, clf in clfs.items():\n",
    "    print(\"=====\"*20)\n",
    "    print(f\"{name} classifier\\n\")\n",
    "    fit_compute_importance(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fccc4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Early\"] = df[DIF_MIN].shift(-1)\n",
    "df.loc[df[\"Early\"]>=0, 'AnteriorEarly'] = 0\n",
    "df.loc[df[\"Early\"]<0, 'AnteriorEarly'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6fd147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732b3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea102ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17b3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906042bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768f065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f993d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d57ce51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa2629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d636a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c481ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a86efd83",
   "metadata": {},
   "source": [
    "# adding new feature \n",
    "parece que est치 mal el after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a937f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../sources/raw/dataset_SCL.csv\", dtype={'Vlo-O':str, 'Vlo-I':str})\n",
    "df[FECHAO] = pd.to_datetime(df[FECHAO])\n",
    "df = (df.pipe(split_date, FECHAI)\n",
    "        .pipe(add_temporada_alta_flag, dates)\n",
    "        .pipe(add_periodo_dia_flag, times)\n",
    "        #.pipe(apply_cohort)\n",
    "        .pipe(add_dif_min_and_atraso_15)\n",
    "        .pipe(delete_operational_columns)\n",
    "        .pipe(filter_column)\n",
    "        .pipe(to_bool_tipo_vuelo)\n",
    "        .pipe(one_hot_encoder) # generate one_hot_encoder\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "63ab5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(FECHAI, inplace = True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df['deltaF'] = df[FECHAI].diff()\n",
    "df['deltaF_s']  = df.deltaF.dt.seconds\n",
    "df.loc[(df['deltaF_s'].isna()) & (df[ATRASO_15]==1), 'deltaF_s'] = 15*60\n",
    "df.loc[(df['deltaF_s'].isna()), 'deltaF_s'] = 0\n",
    "df['deltaF_s']  = df.deltaF_s.astype(int)\n",
    "df['Anterior'] = 0\n",
    "df.loc[df.deltaF_s>15*60, 'Anterior']= 1\n",
    "del df['deltaF']\n",
    "del df['deltaF_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c97563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "columns = columns.tolist()\n",
    "columns.remove(FECHAI)\n",
    "df = df[columns]\n",
    "columns.remove(ATRASO_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af2437dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[columns],\n",
    "        df[ATRASO_15],\n",
    "        test_size=.8,\n",
    "        random_state=42,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f41c6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 4 new classifiers\n",
    "clfs = {\"Logistic Regression\": LogisticRegression(solver = 'saga',  random_state=0,  max_iter=99999990 ),\n",
    "        \"Support Vector rbf\": SVC(kernel='rbf'),\n",
    "        \"Support Vector sigmoid\": SVC(kernel='sigmoid'),\n",
    "        \"KNN\":KNeighborsClassifier(n_neighbors=15),\n",
    "        \"Decision Tree\": DecisionTreeClassifier()\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a15577d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Logistic Regression classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8181219592297131\n",
      "Mean accuracy score on the test set: 81.43%\n",
      "\n",
      "====================================================================================================\n",
      "Support Vector rbf classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8181219592297131\n",
      "Mean accuracy score on the test set: 81.43%\n",
      "\n",
      "====================================================================================================\n",
      "Support Vector sigmoid classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8181219592297131\n",
      "Mean accuracy score on the test set: 81.43%\n",
      "\n",
      "====================================================================================================\n",
      "KNN classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8197345830420986\n",
      "Mean accuracy score on the test set: 81.42%\n",
      "\n",
      "====================================================================================================\n",
      "Decision Tree classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.7469394343468733\n",
      "Mean accuracy score on the test set: 74.78%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for name, clf in clfs.items():\n",
    "    print(\"=====\"*20)\n",
    "    print(f\"{name} classifier\\n\")\n",
    "    fit_compute_importance(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5653cd60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Logistic Regression classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8181219592297131\n",
      "Mean accuracy score on the test set: 81.43%\n",
      "\n",
      "====================================================================================================\n",
      "Support Vector rbf classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8181219592297131\n",
      "Mean accuracy score on the test set: 81.43%\n",
      "\n",
      "====================================================================================================\n",
      "Support Vector sigmoid classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8181219592297131\n",
      "Mean accuracy score on the test set: 81.43%\n",
      "\n",
      "====================================================================================================\n",
      "KNN classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.8159226747000174\n",
      "Mean accuracy score on the test set: 81.28%\n",
      "\n",
      "====================================================================================================\n",
      "Decision Tree classifier\n",
      "\n",
      "cross-validation Avg accuracy: 0.7457668221924754\n",
      "Mean accuracy score on the test set: 74.26%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for name, clf in clfs.items():\n",
    "    print(\"=====\"*20)\n",
    "    print(f\"{name} classifier\\n\")\n",
    "    fit_compute_importance(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60681c1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8170438926051499"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_st = RandomForestClassifier(random_state=42)\n",
    "model = fit_grid_model(rfc_st, PARAM_GRID, X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f06e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
