{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a54a8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown as md\n",
    "from datetime import date, datetime\n",
    "%matplotlib inline\n",
    "#sns.set(rc={\"figure.figsize\":(20, 20)})\n",
    "\n",
    "from pandas import DataFrame\n",
    "from typing import List\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d3a747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7da16614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS\n",
    "FECHAI = 'Fecha-I'\n",
    "FECHAO = 'Fecha-O'\n",
    "VLOO = 'Vlo-O'\n",
    "ORIO = 'Ori-O'\n",
    "DESO = 'Des-O'\n",
    "EMPO = 'Emp-O'\n",
    "VLOI = 'Vlo-I'\n",
    "DIA = 'DIA'\n",
    "MES = 'MES'\n",
    "ANIO = 'AÑO'\n",
    "DIANOM = 'DIANOM'\n",
    "TIPOVUELO = 'TIPOVUELO'\n",
    "OPERA = 'OPERA'\n",
    "SIGLADES = 'SIGLADES'\n",
    "COHORT = 'cohort'\n",
    "# \n",
    "TEMPORADA_ALTA = 'temporada_alta'\n",
    "DIF_MIN = 'dif_min'\n",
    "ATRASO_15 = 'atraso_15'\n",
    "PERIODO_DIA = 'periodo_dia'\n",
    "MORNING = 'mañana'\n",
    "AFTERNOON = 'tarde'\n",
    "NIGHT = 'noche'\n",
    "\n",
    "COL_TEMPORAL = 'col_tmp'\n",
    "\n",
    "DATE = 'Date'\n",
    "TIME = 'time'\n",
    "HOUR = 'hour'\n",
    "MINUTE = 'minute'\n",
    "\n",
    "\n",
    "COLUM_FILTER = [FECHAI,VLOI, DIA, MES, ANIO, DIANOM, \n",
    "                TIPOVUELO, OPERA, SIGLADES, TEMPORADA_ALTA, ATRASO_15, PERIODO_DIA,\n",
    "                 'AnteriorDelay', 'AnteriorEarly', 'number_of_flights_same_opera',\n",
    "                'number_of_flights_before', 'number_of_flights_same_dest']\n",
    "\n",
    "COLUM_SYNTHETIC_FEATURES = [TEMPORADA_ALTA, DIF_MIN, ATRASO_15, PERIODO_DIA]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "STR_WINTER_START = '2017-12-15'\n",
    "STR_WINTER_END = '2017-12-31'\n",
    "STR_WINTER_BIS_START = '2017-01-01'\n",
    "STR_WINTER_BIS_END = '2017-03-03'\n",
    "STR_JULY_START = '2017-07-15'\n",
    "STR_JULY_END = '2017-07-31'\n",
    "STR_SEPT_START = '2017-09-11'\n",
    "STR_SEPT_END = '2017-09-30'\n",
    "\n",
    "\n",
    "STR_MANANA_START= '5:00'\n",
    "STR_MANANA_END = '11:59'\n",
    "STR_TARDE_START = '12:00'\n",
    "STR_TARDE_END = '18:59'\n",
    "\n",
    "PARAM_GRID = {\n",
    "    'n_estimators': [10, 20, 50, 10, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [4, 8, 16, 32, 64, 128, 256, 512],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_jobs': [2]\n",
    "}\n",
    "\n",
    "\n",
    "columns = [TEMPORADA_ALTA, DIF_MIN, ATRASO_15, PERIODO_DIA]\n",
    "def convert_str_to_date(str_date: str) -> datetime:\n",
    "    \"\"\"convert string to date format '%Y-%m-%d'\n",
    "\n",
    "    Args:\n",
    "        str_date (str): string ex: '2017-01-01'\n",
    "\n",
    "    Returns:\n",
    "        datetime: string with datetime type\n",
    "    \"\"\"\n",
    "    return datetime.strptime(str_date, '%Y-%m-%d').date()\n",
    "\n",
    "def convert_str_to_time(str_date: str) -> datetime:\n",
    "    \"\"\"convert string to time format '%H:%M'\n",
    "\n",
    "    Args:\n",
    "        str_date (str): string '23:59'\n",
    "\n",
    "    Returns:\n",
    "        datetime: string with datetime type\n",
    "    \"\"\"\n",
    "    return datetime.strptime(str_date, '%H:%M').time()\n",
    "\n",
    "def add_temporada_alta_flag(df: DataFrame, dates: List) -> DataFrame:\n",
    "    \"\"\"Add temporada alta flag according to array of dates\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): _description_\n",
    "        dates (List): _description_\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: _description_\n",
    "    \"\"\"\n",
    "    df[TEMPORADA_ALTA] = 0\n",
    "    for date in dates:\n",
    "        df.loc[(df[DATE] >= date[0]) & (df[DATE]<=date[1]), TEMPORADA_ALTA] = 1\n",
    "    return df.copy()\n",
    "def add_periodo_dia_flag(df: DataFrame, times: List) -> DataFrame:\n",
    "    \"\"\"Add temporada alta flag according to array of dates\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): _description_\n",
    "        dates (List): _description_\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: _description_\n",
    "    \"\"\"\n",
    "    # default\n",
    "    df[PERIODO_DIA] = NIGHT\n",
    "    df.loc[(df[TIME] >= times[0][0]) & (df[TIME]<=times[0][1]), PERIODO_DIA] = MORNING\n",
    "    df.loc[(df[TIME] >= times[1][0]) & (df[TIME]<=times[1][1]), PERIODO_DIA] = AFTERNOON\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac15a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temporada_alta_set()-> list:\n",
    "    \"\"\"\n",
    "    This function generate arrays to generate temporada_alta elements, source from constant\n",
    "    dates ahre the following, \n",
    "        15-Dic y 3-Mar, o 15-Jul y 31-Jul, o 11-Sep y 30-Sep,\n",
    "    output: array of element, with the following \n",
    "    \"\"\"\n",
    "    str_winter_start = convert_str_to_date(STR_WINTER_START)\n",
    "    str_winter_end = convert_str_to_date(STR_WINTER_END)\n",
    "    str_winter_bis_start = convert_str_to_date(STR_WINTER_BIS_START)\n",
    "    str_winter_bis_end = convert_str_to_date(STR_WINTER_BIS_END)\n",
    "    str_July_start = convert_str_to_date(STR_JULY_START)\n",
    "    str_July_end = convert_str_to_date(STR_JULY_END)\n",
    "    str_Sept_start = convert_str_to_date(STR_SEPT_START)\n",
    "    str_Sept_end = convert_str_to_date(STR_SEPT_END)\n",
    "\n",
    "    dates = [[str_winter_start, str_winter_end],\n",
    "             [str_winter_bis_start, str_winter_bis_end],\n",
    "             [str_July_start, str_July_end],\n",
    "             [str_Sept_start, str_Sept_end]]\n",
    "    return dates\n",
    "\n",
    "def generate_day_section():\n",
    "    \"\"\"\n",
    "    split a day iin three part, morning, afternoon and night\n",
    "    \"\"\"\n",
    "    str_mañana_start = convert_str_to_time(STR_MANANA_START)\n",
    "    str_mañana_end = convert_str_to_time(STR_MANANA_END)\n",
    "    str_tarde_start = convert_str_to_time(STR_TARDE_START)\n",
    "    str_tarde_end = convert_str_to_time(STR_TARDE_END)\n",
    "    times = [[str_mañana_start, str_mañana_end],\n",
    "             [str_tarde_start, str_tarde_end],\n",
    "            ]\n",
    "    return times\n",
    "\n",
    "def split_date(df:DataFrame, column_name:str)-> DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): _description_\n",
    "        column_name (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: _description_\n",
    "    \"\"\"\n",
    "    df[column_name] = pd.to_datetime(df[column_name])\n",
    "    df[DATE] = df[column_name].dt.date\n",
    "    df[TIME] = df[column_name].dt.time\n",
    "    return df.copy()\n",
    "\n",
    "def add_temporada_alta_flag(df: DataFrame, dates: List) -> DataFrame:\n",
    "    \"\"\"Add temporada alta flag according to array of dates\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): _description_\n",
    "        dates (List): _description_\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: _description_\n",
    "    \"\"\"\n",
    "    df[TEMPORADA_ALTA] = 0\n",
    "    for date in dates:\n",
    "        df.loc[(df[DATE] >= date[0]) & (df[DATE]<=date[1]), TEMPORADA_ALTA] = 1\n",
    "    return df.copy()\n",
    "\n",
    "def add_periodo_dia_flag(df: DataFrame, times: List) -> DataFrame:\n",
    "    \"\"\"Add temporada alta flag according to array of dates\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): _description_\n",
    "        dates (List): _description_\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: _description_\n",
    "    \"\"\"\n",
    "    # default\n",
    "    df[PERIODO_DIA] = NIGHT\n",
    "    df.loc[(df[TIME] >= times[0][0]) & (df[TIME]<=times[0][1]), PERIODO_DIA] = MORNING\n",
    "    df.loc[(df[TIME] >= times[1][0]) & (df[TIME]<=times[1][1]), PERIODO_DIA] = AFTERNOON\n",
    "    return df.copy()\n",
    "\n",
    "def add_dif_min_and_atraso_15(df:DataFrame) ->DataFrame:\n",
    "    df[DIF_MIN] = df[FECHAO]-df[FECHAI]\n",
    "    df[DIF_MIN] = df[DIF_MIN].dt.total_seconds()//60\n",
    "    df[ATRASO_15] = 0\n",
    "    df.loc[df[DIF_MIN]>15, ATRASO_15] = 1\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6d0b4404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_operational_columns(df:DataFrame)-> DataFrame:\n",
    "    del df[FECHAO]\n",
    "    del df[VLOO]\n",
    "    del df[ORIO]\n",
    "    del df[DESO]\n",
    "    del df[EMPO]\n",
    "    return df\n",
    "\n",
    "def filter_column(df:DataFrame, columns:str =  COLUM_FILTER)->DataFrame:\n",
    "    return df[columns]\n",
    "\n",
    "\n",
    "def previous_flight (df):\n",
    "    df.sort_values(FECHAI, inplace = True)\n",
    "    df[\"Early\"] = df[DIF_MIN].shift(1)\n",
    "    df['AnteriorEarly'] = 0\n",
    "    df.loc[df[\"Early\"]<0, 'AnteriorEarly'] = 1\n",
    "    df.loc[df['AnteriorEarly'].isna(), 'AnteriorEarly'] = 0\n",
    "    df[\"Delay\"] = df[DIF_MIN].shift(1)\n",
    "    df['AnteriorDelay'] = 0\n",
    "    df.loc[df[\"Delay\"]>0, 'AnteriorDelay'] = 1\n",
    "    del df['Delay']\n",
    "    del df['Early']\n",
    "    return df\n",
    "\n",
    "def number_of_flights_before (df):\n",
    "\n",
    "    df.sort_values(FECHAI, inplace = True)\n",
    "    dft = df.groupby([FECHAI])[FECHAI].count().rename(\"col_tmp\")\n",
    "    dft = dft.reset_index()\n",
    "    dft[\"number_of_flights_before\"] = dft[\"col_tmp\"].shift(1)\n",
    "    del dft['col_tmp']\n",
    "    df = pd.merge(df,dft)\n",
    "    df.loc[df['number_of_flights_before'].isna(), 'number_of_flights_before'] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def number_of_flights_same_opera(df):\n",
    "    dft = df.groupby([FECHAI, 'OPERA'])[FECHAI].count().rename(\"number_of_flights_same_opera\")\n",
    "    dft = dft.reset_index()\n",
    "    dft['number_of_flights_same_opera'] = dft['number_of_flights_same_opera'] -1 \n",
    "    df = pd.merge(df,dft)\n",
    "    df.loc[df['number_of_flights_same_opera'].isna(), 'number_of_flights_same_opera'] = 0\n",
    "    return df\n",
    "\n",
    "def number_of_flights_same_dest(df):\n",
    "    dft = df.groupby([FECHAI, 'SIGLADES'])[FECHAI].count().rename(\"number_of_flights_same_dest\")\n",
    "    dft = dft.reset_index()\n",
    "    dft['number_of_flights_same_dest'] = dft['number_of_flights_same_dest'] -1 \n",
    "    df = pd.merge(df,dft)\n",
    "    df.loc[df['number_of_flights_same_dest'].isna(), 'number_of_flights_same_dest'] = 0\n",
    "    return df\n",
    "\n",
    "def one_hot_encoder(df:DataFrame)-> DataFrame:\n",
    "    \n",
    "    df = pd.get_dummies(df, columns = [OPERA])\n",
    "    df = pd.get_dummies(df, columns = [SIGLADES])\n",
    "    df = pd.get_dummies(df, columns = [TEMPORADA_ALTA]) \n",
    "    df = pd.get_dummies(df, columns = [PERIODO_DIA]) \n",
    "    df = pd.get_dummies(df, columns = [VLOI])\n",
    "    df = pd.get_dummies(df, columns = [DIANOM])\n",
    "    return df \n",
    "\n",
    "\n",
    "def to_bool_tipo_vuelo(df:DataFrame)-> DataFrame:\n",
    "    df[f\"{TIPOVUELO}_\"] = df[TIPOVUELO]\n",
    "    df.loc[df[f\"{TIPOVUELO}_\"]== 'I', TIPOVUELO] = 1\n",
    "    df.loc[df[f\"{TIPOVUELO}_\"]== 'N', TIPOVUELO] = 0\n",
    "    del df[f\"{TIPOVUELO}_\"]\n",
    "    return df\n",
    "\n",
    "def fit_grid_model(\n",
    "    rfc: RandomForestClassifier,\n",
    "    param_grid,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "):  # pragma: no cover\n",
    "    \"\"\"GridSeach\n",
    "\n",
    "    Args:\n",
    "        rfc (RandomForestClassifier): ML Model\n",
    "        param_grid (dict): JSON parameters\n",
    "        X_train (pd.DataFrame): train df\n",
    "        y_train (pd.DataFrame): goal df\n",
    "        model_type (str): model name\n",
    "\n",
    "    Returns:\n",
    "        [type]: model trained\n",
    "    \"\"\"\n",
    "    model = GridSearchCV(\n",
    "        estimator=rfc,\n",
    "        param_grid=param_grid,\n",
    "        cv=3,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0a436732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_compute_importance(clf, X, y, X_test, y_test, k = 4):\n",
    "    kf = KFold(n_splits=4)\n",
    "    kf.get_n_splits(X)\n",
    "    for i in range(0,5):\n",
    "        print(f\"iteration: {i}\")\n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "            X_train_, X_test_ = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train_, y_test_ = y.iloc[train_index], y.iloc[test_index]\n",
    "            clf.fit(X_train_, y_train_)\n",
    "            y_pred = clf.predict(X_test_)\n",
    "    \n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(f\"f1 score test set: {f1_score(y_test, y_pred, zero_division=1)*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dd14bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = generate_temporada_alta_set()\n",
    "times = generate_day_section()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850e63f",
   "metadata": {},
   "source": [
    "no sirven\n",
    "* Ori-I y Pri-o un sólo lugar de origen\n",
    "* Des-I y SIGLADES son lo mismo\n",
    "- OPERA == Emp-I\n",
    "\n",
    "modificadores\n",
    "- Vlo-I != Vlo-O, es diferente hubo atrasosi el número de vuelo cambio o el origen cambio, significa un retraso? Des-I\n",
    "- Des-I != Des-O, es diferente, atraso\n",
    "# no se usaran para evitar sesgos\n",
    "- Fecha-O\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eff828",
   "metadata": {},
   "source": [
    "# All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "66005ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../sources/raw/dataset_SCL.csv\", dtype={'Vlo-O':str, 'Vlo-I':str})\n",
    "df[FECHAO] = pd.to_datetime(df[FECHAO])\n",
    "df = (df.pipe(split_date, FECHAI)\n",
    "        .pipe(add_temporada_alta_flag, dates)\n",
    "        .pipe(add_periodo_dia_flag, times)\n",
    "        #.pipe(apply_cohort)\n",
    "        .pipe(add_dif_min_and_atraso_15)\n",
    "        .pipe(delete_operational_columns)\n",
    "        .pipe(previous_flight)\n",
    "        .pipe(number_of_flights_before)\n",
    "        .pipe(number_of_flights_same_opera)\n",
    "        .pipe(number_of_flights_same_dest)\n",
    "        .pipe(filter_column, COLUM_FILTER)\n",
    "        .pipe(to_bool_tipo_vuelo)\n",
    "        .pipe(one_hot_encoder) # generate one_hot_encoder\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3b9c110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "columns = columns.tolist()\n",
    "columns.remove(FECHAI)\n",
    "df = df[columns]\n",
    "columns.remove(ATRASO_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dc00b2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ATRASO_15].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "220fa856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIA</th>\n",
       "      <th>MES</th>\n",
       "      <th>AÑO</th>\n",
       "      <th>TIPOVUELO</th>\n",
       "      <th>AnteriorDelay</th>\n",
       "      <th>AnteriorEarly</th>\n",
       "      <th>number_of_flights_same_opera</th>\n",
       "      <th>number_of_flights_before</th>\n",
       "      <th>number_of_flights_same_dest</th>\n",
       "      <th>OPERA_Aerolineas Argentinas</th>\n",
       "      <th>...</th>\n",
       "      <th>Vlo-I_993</th>\n",
       "      <th>Vlo-I_9955</th>\n",
       "      <th>Vlo-I_9956</th>\n",
       "      <th>DIANOM_Domingo</th>\n",
       "      <th>DIANOM_Jueves</th>\n",
       "      <th>DIANOM_Lunes</th>\n",
       "      <th>DIANOM_Martes</th>\n",
       "      <th>DIANOM_Miercoles</th>\n",
       "      <th>DIANOM_Sabado</th>\n",
       "      <th>DIANOM_Viernes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68201</th>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68202</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68203</th>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68204</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68205</th>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68206 rows × 690 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DIA  MES   AÑO TIPOVUELO  AnteriorDelay  AnteriorEarly  \\\n",
       "0        1    1  2017         1              0              0   \n",
       "1        1    1  2017         1              0              1   \n",
       "2        1    1  2017         1              0              1   \n",
       "3        1    1  2017         1              1              0   \n",
       "4        1    1  2017         1              1              0   \n",
       "...    ...  ...   ...       ...            ...            ...   \n",
       "68201   31   12  2017         1              0              1   \n",
       "68202    1    1  2018         1              1              0   \n",
       "68203   31   12  2017         1              1              0   \n",
       "68204    1    1  2018         1              0              1   \n",
       "68205   31   12  2017         1              1              0   \n",
       "\n",
       "       number_of_flights_same_opera  number_of_flights_before  \\\n",
       "0                                 0                       0.0   \n",
       "1                                 0                       1.0   \n",
       "2                                 0                       1.0   \n",
       "3                                 0                       1.0   \n",
       "4                                 0                       1.0   \n",
       "...                             ...                       ...   \n",
       "68201                             0                       1.0   \n",
       "68202                             0                       2.0   \n",
       "68203                             0                       1.0   \n",
       "68204                             0                       1.0   \n",
       "68205                             0                       1.0   \n",
       "\n",
       "       number_of_flights_same_dest  OPERA_Aerolineas Argentinas  ...  \\\n",
       "0                                0                            0  ...   \n",
       "1                                0                            0  ...   \n",
       "2                                0                            0  ...   \n",
       "3                                0                            0  ...   \n",
       "4                                0                            0  ...   \n",
       "...                            ...                          ...  ...   \n",
       "68201                            0                            0  ...   \n",
       "68202                            0                            0  ...   \n",
       "68203                            0                            0  ...   \n",
       "68204                            0                            0  ...   \n",
       "68205                            0                            0  ...   \n",
       "\n",
       "       Vlo-I_993  Vlo-I_9955  Vlo-I_9956  DIANOM_Domingo  DIANOM_Jueves  \\\n",
       "0              0           0           0               1              0   \n",
       "1              0           0           0               1              0   \n",
       "2              0           0           0               1              0   \n",
       "3              0           0           0               1              0   \n",
       "4              0           0           0               1              0   \n",
       "...          ...         ...         ...             ...            ...   \n",
       "68201          0           0           0               1              0   \n",
       "68202          0           0           0               0              0   \n",
       "68203          0           0           0               1              0   \n",
       "68204          0           0           0               0              0   \n",
       "68205          0           0           0               1              0   \n",
       "\n",
       "       DIANOM_Lunes  DIANOM_Martes  DIANOM_Miercoles  DIANOM_Sabado  \\\n",
       "0                 0              0                 0              0   \n",
       "1                 0              0                 0              0   \n",
       "2                 0              0                 0              0   \n",
       "3                 0              0                 0              0   \n",
       "4                 0              0                 0              0   \n",
       "...             ...            ...               ...            ...   \n",
       "68201             0              0                 0              0   \n",
       "68202             1              0                 0              0   \n",
       "68203             0              0                 0              0   \n",
       "68204             1              0                 0              0   \n",
       "68205             0              0                 0              0   \n",
       "\n",
       "       DIANOM_Viernes  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "68201               0  \n",
       "68202               0  \n",
       "68203               0  \n",
       "68204               0  \n",
       "68205               0  \n",
       "\n",
       "[68206 rows x 690 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ac9239a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[columns],\n",
    "        df[ATRASO_15],\n",
    "        test_size=.8,\n",
    "        random_state=42,\n",
    "        stratify = df[ATRASO_15]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a8ccfd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 4 new classifiers\n",
    "clfs = {#\"Logistic Regression\": LogisticRegression(solver = 'saga',  random_state=0,  max_iter=99 ),\n",
    "        \"Support Vector rbf\": SVC(kernel='rbf'),\n",
    "        \"Support Vector sigmoid\": SVC(kernel='sigmoid'),\n",
    "        \"KNN\":KNeighborsClassifier(n_neighbors=15),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"GradientBoostingClassifier\": GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                 max_depth=1, random_state=42)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c484ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "eb275cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b28a3599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Support Vector rbf classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "====================================================================================================\n",
      "Support Vector sigmoid classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "====================================================================================================\n",
      "KNN classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 9.94%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 9.94%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 9.94%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 9.94%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 9.94%\n",
      "\n",
      "====================================================================================================\n",
      "Decision Tree classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 28.51%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 28.42%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 28.56%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 28.52%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 28.81%\n",
      "\n",
      "====================================================================================================\n",
      "GradientBoostingClassifier classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 18.43%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 18.43%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 18.43%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 18.43%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 18.43%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "for name, clf in clfs.items():\n",
    "    print(\"=====\"*20)\n",
    "    print(f\"{name} classifier\\n\")\n",
    "    \n",
    "    sm = SMOTE(k_neighbors=5)\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    #fit_compute_importance(clf, X_train, y_train, X_test, y_test, k = 4)\n",
    "    fit_compute_importance(clf, X_train_oversampled, y_train_oversampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f31ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656f5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea055f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e61f45d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[columns],\n",
    "        df[ATRASO_15],\n",
    "        test_size=.8,\n",
    "        random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d6c90f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 4 new classifiers\n",
    "clfs = {#\"Logistic Regression\": LogisticRegression(solver = 'saga',  random_state=0,  max_iter=99 ),\n",
    "        \"Support Vector rbf\": SVC(kernel='rbf'),\n",
    "        \"Support Vector sigmoid\": SVC(kernel='sigmoid'),\n",
    "        \"KNN\":KNeighborsClassifier(n_neighbors=15),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"GradientBoostingClassifier\": GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                 max_depth=1, random_state=42)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e6880e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d7085b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "daa58988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Support Vector rbf classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "====================================================================================================\n",
      "Support Vector sigmoid classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "====================================================================================================\n",
      "KNN classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 9.96%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 9.96%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 9.96%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 9.96%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 9.96%\n",
      "\n",
      "====================================================================================================\n",
      "Decision Tree classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 27.76%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 27.65%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 27.99%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 28.01%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 28.29%\n",
      "\n",
      "====================================================================================================\n",
      "GradientBoostingClassifier classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 17.81%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 17.81%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 17.81%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 17.81%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 17.81%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "for name, clf in clfs.items():\n",
    "    print(\"=====\"*20)\n",
    "    print(f\"{name} classifier\\n\")\n",
    "    \n",
    "    sm = SMOTE(k_neighbors=5)\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    #fit_compute_importance(clf, X_train, y_train, X_test, y_test, k = 4)\n",
    "    fit_compute_importance(clf, X_train_oversampled, y_train_oversampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef1ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b219cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c04fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "84ca8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[columns],\n",
    "        df[ATRASO_15],\n",
    "        test_size=.8,\n",
    "        random_state=42,\n",
    "        stratify = df[ATRASO_15]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9f8f8a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 4 new classifiers\n",
    "clfs = {#\"Logistic Regression\": LogisticRegression(solver = 'saga',  random_state=0,  max_iter=99 ),\n",
    "        \"Support Vector rbf\": SVC(kernel='rbf'),\n",
    "        \"Support Vector sigmoid\": SVC(kernel='sigmoid'),\n",
    "        \"KNN\":KNeighborsClassifier(n_neighbors=15),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"GradientBoostingClassifier\": GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                 max_depth=1, random_state=42)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "50d61e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9afaecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b6559f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Support Vector rbf classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "====================================================================================================\n",
      "Support Vector sigmoid classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 0.00%\n",
      "\n",
      "====================================================================================================\n",
      "KNN classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 9.96%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 9.96%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 9.96%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 9.96%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 9.96%\n",
      "\n",
      "====================================================================================================\n",
      "Decision Tree classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 28.03%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 28.24%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 28.21%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 27.56%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 28.34%\n",
      "\n",
      "====================================================================================================\n",
      "GradientBoostingClassifier classifier\n",
      "\n",
      "iteration: 0\n",
      "f1 score test set: 17.81%\n",
      "\n",
      "iteration: 1\n",
      "f1 score test set: 17.81%\n",
      "\n",
      "iteration: 2\n",
      "f1 score test set: 17.81%\n",
      "\n",
      "iteration: 3\n",
      "f1 score test set: 17.81%\n",
      "\n",
      "iteration: 4\n",
      "f1 score test set: 17.81%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "for name, clf in clfs.items():\n",
    "    print(\"=====\"*20)\n",
    "    print(f\"{name} classifier\\n\")\n",
    "    \n",
    "    \n",
    "    #fit_compute_importance(clf, X_train, y_train, X_test, y_test, k = 4)\n",
    "    fit_compute_importance(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3d73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcdeb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6d2e8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "beb81b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81266497 0.12878776 0.00430308 0.00403015 0.00397122 0.00369971\n",
      " 0.00353327 0.00328659 0.00260366 0.0018815 ]\n",
      "[1033.13013499  411.27902755   75.17771933   72.75451877   72.22058661\n",
      "   69.70803813   68.12208643   65.70101133   58.47786571   49.71093624]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8b36921",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_pca = scaler.transform(X_train)\n",
    "X_test_pca = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c79aa3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Decision Tree classifier\n",
      "\n",
      "Mean accuracy score on the test set: 74.09%\n",
      "\n",
      "====================================================================================================\n",
      "GradientBoostingClassifier classifier\n",
      "\n",
      "Mean accuracy score on the test set: 81.43%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for name, clf in clfs.items():\n",
    "    print(\"=====\"*20)\n",
    "    print(f\"{name} classifier\\n\")\n",
    "    fit_compute_importance(clf, X_train_pca, y_train, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "42d02acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "910de1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_st = RandomForestClassifier(random_state=42)\n",
    "model = fit_grid_model(rfc_st, PARAM_GRID, X_train_pca, y_train)\n",
    "y_pred = model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36db2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8e4e707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30ef0e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11846565566458521"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred,labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67bbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feat_importances = pd.DataFrame(clf.feature_importances_, index=X_train.columns, columns=[\"Importance\"])\n",
    "feat_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "feat_importances.plot(kind='bar', figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f88deca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
